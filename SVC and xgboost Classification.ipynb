{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T00:29:22.257083Z",
     "start_time": "2018-01-30T00:29:21.814534Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "np.set_printoptions(precision=4,suppress=True)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T00:29:22.364462Z",
     "start_time": "2018-01-30T00:29:22.259251Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = pickle.load(open('documents.pl','rb')) #document is the contents of each tweet stored in rows of an array\n",
    "tags = pickle.load(open('tags.pl','rb'))#tag cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T00:29:43.212061Z",
     "start_time": "2018-01-30T00:29:22.367723Z"
    }
   },
   "outputs": [],
   "source": [
    "# bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "BoW = CountVectorizer(documents, strip_accents='unicode', ngram_range=(1,3), min_df=3)#vectorizing the words within 1 to 3 alphabets (1-3Ngram) range \n",
    "X_bag = BoW.fit_transform(documents)\n",
    "tf_transformer = TfidfTransformer().fit(X_bag) #weighted term frequency with their presence in each document\n",
    "X_bag = tf_transformer.fit_transform(X_bag) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T00:29:43.240166Z",
     "start_time": "2018-01-30T00:29:43.214235Z"
    }
   },
   "outputs": [],
   "source": [
    "Y = np.array(np.array(tags)=='Prio-Fall', dtype=int)#makng an array that will be our binary-Y (to be predicted) element. it basically\n",
    "                                                    #says the cases that are priority while others are not priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T00:29:43.263300Z",
     "start_time": "2018-01-30T00:29:43.242461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1450676982591876"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y)/len(Y) # just to see how polirized is the data. too few priority cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T00:29:43.998242Z",
     "start_time": "2018-01-30T00:29:43.621889Z"
    }
   },
   "outputs": [],
   "source": [
    "#import xgboost as xgb\n",
    "# Code for cross-validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T01:09:41.412901Z",
     "start_time": "2018-01-30T01:09:41.397544Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SVC for challenge 1A\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.4938679245283019\n",
      "F1 score: 0.4915346805024576\n",
      "F1 score: 0.4882916863114883\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "kfold = StratifiedKFold(Y, k, shuffle=True, random_state=0) #test and train cases are made from within the data\n",
    "\n",
    "results = np.zeros((k,3))\n",
    "cv = CountVectorizer(min_df = 3, max_df = 10000, ngram_range=(1, 3), lowercase =True)\n",
    "tfidfTransform = TfidfTransformer()\n",
    "\n",
    "# iterate over two folds\n",
    "compareScores = 0\n",
    "finalSVCModel = LinearSVC(dual=False,tol=1e-3, class_weight = 'balanced')\n",
    "for i, (train_ind, test_ind) in enumerate(kfold):\n",
    "    model = LinearSVC(dual=False,tol=1e-3, class_weight = 'balanced') \n",
    "    \n",
    "    trainContent = list( documents[i] for i in train_ind )\n",
    "    train_counts = cv.fit_transform(trainContent)\n",
    "    \n",
    "    train_tfidf = tfidfTransform.fit_transform(train_counts)\n",
    "    \n",
    "    testContent = list(documents[i] for i in test_ind)\n",
    "    test_counts = cv.transform(testContent)\n",
    "    \n",
    "    test_tfidf = tfidfTransform.transform(test_counts)\n",
    "    \n",
    "    trainLabel = list( Y[i] for i in train_ind )\n",
    "    model.fit(train_tfidf, trainLabel)\n",
    "    \n",
    "    pred = model.predict(test_tfidf)\n",
    "    \n",
    "    testLabel = list( Y[i] for i in test_ind )\n",
    "    currentScore = f1_score(testLabel, pred)\n",
    "    \n",
    "    if(currentScore > compareScores):\n",
    "        compareScores = currentScore\n",
    "        finalSVCModel = model\n",
    "    \n",
    "    print(\"F1 score:\", currentScore)\n",
    "    \n",
    "\n",
    "filename = 'finalized_model_SVC.sav'\n",
    "pickle.dump(finalSVCModel, open(filename, 'wb'))\n",
    "pickle.dump(cv,open('countVectorizationSVC.sav','wb'))\n",
    "pickle.dump(tfidfTransform,open('tfidfTransformSVC.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pickle.load(open('documents_testing.pl','rb'))\n",
    "content = list( documents[i] for i in range(len(documents)) )\n",
    "counts = cv.transform(content)\n",
    "    \n",
    "tfidf = tfidfTransform.transform(counts)\n",
    "\n",
    "pred = model.predict(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T01:51:03.100204Z",
     "start_time": "2018-01-30T01:51:02.906833Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set our parameters for xgboost\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.07\n",
    "params['max_depth'] = 50\n",
    "params['min_child_weight'] = 6\n",
    "params['lambda'] = 1\n",
    "params['nthread'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-30T01:51:24.365Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124348, 321767) (36363, 321767) (124348,) (36363,)\n",
      "[0]\ttrain-logloss:0.668219\tvalid-logloss:0.672347\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.516264\tvalid-logloss:0.548634\n",
      "[20]\ttrain-logloss:0.445863\tvalid-logloss:0.495861\n",
      "[30]\ttrain-logloss:0.406458\tvalid-logloss:0.468739\n",
      "[40]\ttrain-logloss:0.382029\tvalid-logloss:0.45344\n",
      "[50]\ttrain-logloss:0.367049\tvalid-logloss:0.44488\n",
      "[60]\ttrain-logloss:0.357191\tvalid-logloss:0.439303\n",
      "[70]\ttrain-logloss:0.349485\tvalid-logloss:0.435291\n",
      "[80]\ttrain-logloss:0.342704\tvalid-logloss:0.431736\n",
      "[90]\ttrain-logloss:0.335843\tvalid-logloss:0.428089\n",
      "[100]\ttrain-logloss:0.330533\tvalid-logloss:0.425454\n",
      "[110]\ttrain-logloss:0.325089\tvalid-logloss:0.422686\n",
      "[120]\ttrain-logloss:0.319438\tvalid-logloss:0.419606\n"
     ]
    }
   ],
   "source": [
    "# Create 2 folds\n",
    "k = 3\n",
    "kfold = StratifiedKFold(Y, k, shuffle=True, random_state=0)\n",
    "\n",
    "results = np.zeros((k,3))\n",
    "\n",
    "# iterate over two folds\n",
    "for i, (train_ind, test_ind) in enumerate(kfold):\n",
    "    X_train, X_val, Y_train, Y_val = X_bag[train_ind], X_bag[test_ind], Y[train_ind], Y[test_ind]\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    X_resampled, Y_resampled = ros.fit_sample(X_train, Y_train)\n",
    "    print(X_resampled.shape, X_val.shape, Y_resampled.shape, Y_val.shape)\n",
    "    \n",
    "    D_train = xgb.DMatrix(X_resampled, label=Y_resampled)\n",
    "    D_val = xgb.DMatrix(X_val, label=Y_val)\n",
    "\n",
    "    watchlist = [(D_train, 'train'), (D_val, 'valid')]\n",
    "    bst = xgb.train(params, D_train, 400, watchlist, early_stopping_rounds=50, verbose_eval=10, )\n",
    "    predictions = bst.predict(data=D_val).round()\n",
    "    f1 = f1_score(Y_val, predictions)\n",
    "    acc = accuracy_score(Y_val, predictions)\n",
    "    prio_acc = accuracy_score(Y_val[Y_val==1], predictions[Y_val==1])\n",
    "    results[i] = [f1, acc, prio_acc]\n",
    "    print('f1 score: {}'.format(f1))\n",
    "    print('accuracy: {}\\%'.format(acc))\n",
    "    print('Prio accuracy: {}'.format(prio_acc))\n",
    "    print(confusion_matrix(Y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T00:54:50.343373Z",
     "start_time": "2018-01-30T00:32:33.809Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(results), np.var(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "notify_time": "0"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
